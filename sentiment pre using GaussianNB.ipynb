{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer,word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Finally a transparant silicon case ^^ Thanks t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>We love this! Would you go? #talk #makememorie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm wired I know I'm George I was made that wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>What amazing service! Apple won't even talk to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0  #fingerprint #Pregnancy Test https://goo.gl/h1...\n",
       "1   2      0  Finally a transparant silicon case ^^ Thanks t...\n",
       "2   3      0  We love this! Would you go? #talk #makememorie...\n",
       "3   4      0  I'm wired I know I'm George I was made that wa...\n",
       "4   5      1  What amazing service! Apple won't even talk to..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv('train_2kmZucJ.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7920, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eng_stop_words=stopwords.words('english')\n",
    "lem=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tweet):\n",
    "    final_tokens=' '\n",
    "    token_no_url=re.sub(r'http\\S+', ' ',tweet)\n",
    "    token_no_spl= re.sub('[^A-Za-z]+', ' ', token_no_url) \n",
    "    \n",
    "    tokens=word_tokenize(token_no_spl,language='english')\n",
    "    filtered_tokens=[token.lower() for token in tokens if token.lower() not in eng_stop_words]\n",
    "    lemmed_tokens=[lem.lemmatize(token,pos='v') for token in filtered_tokens]\n",
    "    final_tokens=final_tokens.join(lemmed_tokens)\n",
    "    return final_tokens\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fingerprint', 'Pregnancy', 'Test', 'android', 'apps', 'beautiful', 'cute', 'health', 'igers', 'iphoneonly', 'iphonesia', 'iphone']\n",
      "['Finally', 'a', 'transparant', 'silicon', 'case', 'Thanks', 'to', 'my', 'uncle', 'yay', 'Sony', 'Xperia', 'S', 'sonyexperias']\n",
      "['We', 'love', 'this', 'Would', 'you', 'go', 'talk', 'makememories', 'unplug', 'relax', 'iphone', 'smartphone', 'wifi', 'connect']\n"
     ]
    }
   ],
   "source": [
    "train['cleaned_tweets']=train['tweet'].apply(lambda x:preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1...</td>\n",
       "      <td>fingerprint pregnancy test android apps beauti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Finally a transparant silicon case ^^ Thanks t...</td>\n",
       "      <td>finally transparant silicon case thank uncle y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>We love this! Would you go? #talk #makememorie...</td>\n",
       "      <td>love would go talk makememories unplug relax i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm wired I know I'm George I was made that wa...</td>\n",
       "      <td>wire know george make way iphone cute daventry...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>What amazing service! Apple won't even talk to...</td>\n",
       "      <td>amaze service apple even talk question unless ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7915</th>\n",
       "      <td>7916</td>\n",
       "      <td>0</td>\n",
       "      <td>Live out loud #lol #liveoutloud #selfie #smile...</td>\n",
       "      <td>live loud lol liveoutloud selfie smile sony mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7916</th>\n",
       "      <td>7917</td>\n",
       "      <td>0</td>\n",
       "      <td>We would like to wish you an amazing day! Make...</td>\n",
       "      <td>would like wish amaze day make every minute co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7917</th>\n",
       "      <td>7918</td>\n",
       "      <td>0</td>\n",
       "      <td>Helping my lovely 90 year old neighbor with he...</td>\n",
       "      <td>help lovely year old neighbor ipad morning mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7918</th>\n",
       "      <td>7919</td>\n",
       "      <td>0</td>\n",
       "      <td>Finally got my #smart #pocket #wifi stay conne...</td>\n",
       "      <td>finally get smart pocket wifi stay connect any...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7919</th>\n",
       "      <td>7920</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple Barcelona!!! #Apple #Store #BCN #Barcelo...</td>\n",
       "      <td>apple barcelona apple store bcn barcelona trav...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7920 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  label                                              tweet  \\\n",
       "0        1      0  #fingerprint #Pregnancy Test https://goo.gl/h1...   \n",
       "1        2      0  Finally a transparant silicon case ^^ Thanks t...   \n",
       "2        3      0  We love this! Would you go? #talk #makememorie...   \n",
       "3        4      0  I'm wired I know I'm George I was made that wa...   \n",
       "4        5      1  What amazing service! Apple won't even talk to...   \n",
       "...    ...    ...                                                ...   \n",
       "7915  7916      0  Live out loud #lol #liveoutloud #selfie #smile...   \n",
       "7916  7917      0  We would like to wish you an amazing day! Make...   \n",
       "7917  7918      0  Helping my lovely 90 year old neighbor with he...   \n",
       "7918  7919      0  Finally got my #smart #pocket #wifi stay conne...   \n",
       "7919  7920      0  Apple Barcelona!!! #Apple #Store #BCN #Barcelo...   \n",
       "\n",
       "                                         cleaned_tweets  \n",
       "0     fingerprint pregnancy test android apps beauti...  \n",
       "1     finally transparant silicon case thank uncle y...  \n",
       "2     love would go talk makememories unplug relax i...  \n",
       "3     wire know george make way iphone cute daventry...  \n",
       "4     amaze service apple even talk question unless ...  \n",
       "...                                                 ...  \n",
       "7915  live loud lol liveoutloud selfie smile sony mu...  \n",
       "7916  would like wish amaze day make every minute co...  \n",
       "7917  help lovely year old neighbor ipad morning mak...  \n",
       "7918  finally get smart pocket wifi stay connect any...  \n",
       "7919  apple barcelona apple store bcn barcelona trav...  \n",
       "\n",
       "[7920 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets=train['cleaned_tweets']\n",
    "label=train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(tweets,label,test_size=.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer()\n",
    "x_train_mat=tfidf.fit_transform(x_train)\n",
    "x_test_mat=tfidf.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aag</th>\n",
       "      <th>aah</th>\n",
       "      <th>aalborg</th>\n",
       "      <th>aand</th>\n",
       "      <th>aapl</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aaronbrandt</th>\n",
       "      <th>aarp</th>\n",
       "      <th>aarrrggghhhh</th>\n",
       "      <th>...</th>\n",
       "      <th>zunjndm</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zwckahsl</th>\n",
       "      <th>zwcn</th>\n",
       "      <th>zx</th>\n",
       "      <th>zxw</th>\n",
       "      <th>zxzh</th>\n",
       "      <th>zzita</th>\n",
       "      <th>zzjvgtyaxl</th>\n",
       "      <th>zznj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 13910 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa  aag  aah  aalborg  aand  aapl  aaron  aaronbrandt  aarp  aarrrggghhhh  \\\n",
       "0  0.0  0.0  0.0      0.0   0.0   0.0    0.0          0.0   0.0           0.0   \n",
       "1  0.0  0.0  0.0      0.0   0.0   0.0    0.0          0.0   0.0           0.0   \n",
       "2  0.0  0.0  0.0      0.0   0.0   0.0    0.0          0.0   0.0           0.0   \n",
       "3  0.0  0.0  0.0      0.0   0.0   0.0    0.0          0.0   0.0           0.0   \n",
       "4  0.0  0.0  0.0      0.0   0.0   0.0    0.0          0.0   0.0           0.0   \n",
       "\n",
       "   ...  zunjndm  zurich  zwckahsl  zwcn   zx  zxw  zxzh  zzita  zzjvgtyaxl  \\\n",
       "0  ...      0.0     0.0       0.0   0.0  0.0  0.0   0.0    0.0         0.0   \n",
       "1  ...      0.0     0.0       0.0   0.0  0.0  0.0   0.0    0.0         0.0   \n",
       "2  ...      0.0     0.0       0.0   0.0  0.0  0.0   0.0    0.0         0.0   \n",
       "3  ...      0.0     0.0       0.0   0.0  0.0  0.0   0.0    0.0         0.0   \n",
       "4  ...      0.0     0.0       0.0   0.0  0.0  0.0   0.0    0.0         0.0   \n",
       "\n",
       "   zznj  \n",
       "0   0.0  \n",
       "1   0.0  \n",
       "2   0.0  \n",
       "3   0.0  \n",
       "4   0.0  \n",
       "\n",
       "[5 rows x 13910 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_mat_df=pd.DataFrame(x_train_mat.toarray(),columns=tfidf.get_feature_names())\n",
    "x_train_mat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aag',\n",
       " 'aah',\n",
       " 'aalborg',\n",
       " 'aand',\n",
       " 'aapl',\n",
       " 'aaron',\n",
       " 'aaronbrandt',\n",
       " 'aarp',\n",
       " 'aarrrggghhhh',\n",
       " 'aashamsakal',\n",
       " 'aaydojbfkq',\n",
       " 'aayp',\n",
       " 'ab',\n",
       " 'abah',\n",
       " 'abajournal',\n",
       " 'abay',\n",
       " 'abbs',\n",
       " 'abc',\n",
       " 'abdullahoashraf',\n",
       " 'abe',\n",
       " 'aber',\n",
       " 'abercrombie',\n",
       " 'abfad',\n",
       " 'abfadofficial',\n",
       " 'abi',\n",
       " 'ability',\n",
       " 'abit',\n",
       " 'able',\n",
       " 'ableton',\n",
       " 'aboard',\n",
       " 'aboutalook',\n",
       " 'abouttime',\n",
       " 'abouttonight',\n",
       " 'abp',\n",
       " 'abs',\n",
       " 'abscbn',\n",
       " 'absence',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absurd',\n",
       " 'abt',\n",
       " 'abu',\n",
       " 'abudhabi',\n",
       " 'abuja',\n",
       " 'abujacity',\n",
       " 'abujafct',\n",
       " 'abujapeople',\n",
       " 'abujaphones',\n",
       " 'abukamalyasinpic',\n",
       " 'abuse',\n",
       " 'ac',\n",
       " 'academia',\n",
       " 'academy',\n",
       " 'acap',\n",
       " 'acc',\n",
       " 'accelerate',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'accesorios',\n",
       " 'access',\n",
       " 'accessible',\n",
       " 'accessoires',\n",
       " 'accessories',\n",
       " 'accessory',\n",
       " 'accessorypic',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'accompaniment',\n",
       " 'accomplish',\n",
       " 'accord',\n",
       " 'account',\n",
       " 'accountpic',\n",
       " 'accra',\n",
       " 'acct',\n",
       " 'accurate',\n",
       " 'ace',\n",
       " 'acedemy',\n",
       " 'acer',\n",
       " 'acesse',\n",
       " 'achi',\n",
       " 'achieve',\n",
       " 'achievement',\n",
       " 'acknowledge',\n",
       " 'aconcagua',\n",
       " 'acquaintances',\n",
       " 'acquire',\n",
       " 'acquisition',\n",
       " 'acquisto',\n",
       " 'across',\n",
       " 'act',\n",
       " 'acteur',\n",
       " 'action',\n",
       " 'actipatch',\n",
       " 'actitudpositiva',\n",
       " 'activate',\n",
       " 'activation',\n",
       " 'active',\n",
       " 'activision',\n",
       " 'actor',\n",
       " 'actorslife',\n",
       " 'actress',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'acuario',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'adamsandler',\n",
       " 'adapter',\n",
       " 'adaptive',\n",
       " 'adaptor',\n",
       " 'add',\n",
       " 'addict',\n",
       " 'addiction',\n",
       " 'addictive',\n",
       " 'addition',\n",
       " 'addon',\n",
       " 'address',\n",
       " 'addthis',\n",
       " 'ade',\n",
       " 'adequately',\n",
       " 'adeyhdent',\n",
       " 'adf',\n",
       " 'adh',\n",
       " 'adhi',\n",
       " 'adidas',\n",
       " 'adidasoriginals',\n",
       " 'adio',\n",
       " 'aditya',\n",
       " 'adjust',\n",
       " 'adm',\n",
       " 'administration',\n",
       " 'administrator',\n",
       " 'admit',\n",
       " 'adobe',\n",
       " 'adorable',\n",
       " 'adore',\n",
       " 'adornthewicked',\n",
       " 'adrenalina',\n",
       " 'ads',\n",
       " 'adsrrb',\n",
       " 'adult',\n",
       " 'advance',\n",
       " 'advantage',\n",
       " 'adventure',\n",
       " 'advert',\n",
       " 'advertfail',\n",
       " 'advertise',\n",
       " 'advertisement',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'advisor',\n",
       " 'advocare',\n",
       " 'adwords',\n",
       " 'adwyzo',\n",
       " 'adxvld',\n",
       " 'aec',\n",
       " 'aeihvv',\n",
       " 'aeons',\n",
       " 'aerial',\n",
       " 'af',\n",
       " 'afclmrv',\n",
       " 'affie',\n",
       " 'affirmation',\n",
       " 'affirmations',\n",
       " 'affliate',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'afformention',\n",
       " 'afghan',\n",
       " 'afraid',\n",
       " 'afreaid',\n",
       " 'africa',\n",
       " 'afrolatina',\n",
       " 'afterhours',\n",
       " 'afteriplisnationalized',\n",
       " 'afterlight',\n",
       " 'afternoon',\n",
       " 'afterwards',\n",
       " 'ag',\n",
       " 'agafay',\n",
       " 'againpic',\n",
       " 'againstapple',\n",
       " 'agchat',\n",
       " 'age',\n",
       " 'agent',\n",
       " 'agfa',\n",
       " 'aggravate',\n",
       " 'agh',\n",
       " 'aghif',\n",
       " 'agl',\n",
       " 'aglknox',\n",
       " 'agnee',\n",
       " 'agneeadventures',\n",
       " 'ago',\n",
       " 'agony',\n",
       " 'agree',\n",
       " 'agriculture',\n",
       " 'agua',\n",
       " 'agustus',\n",
       " 'agyea',\n",
       " 'agzemenxrd',\n",
       " 'ah',\n",
       " 'aha',\n",
       " 'ahahah',\n",
       " 'ahahaha',\n",
       " 'ahead',\n",
       " 'ahg',\n",
       " 'ahh',\n",
       " 'ahhh',\n",
       " 'ahhhh',\n",
       " 'ahhhhh',\n",
       " 'aholes',\n",
       " 'ahora',\n",
       " 'ahs',\n",
       " 'ai',\n",
       " 'aid',\n",
       " 'aim',\n",
       " 'aimee',\n",
       " 'aimrggouij',\n",
       " 'air',\n",
       " 'airbook',\n",
       " 'aircraft',\n",
       " 'airforce',\n",
       " 'airjordan',\n",
       " 'airmax',\n",
       " 'airpads',\n",
       " 'airplane',\n",
       " 'airplanes',\n",
       " 'airpods',\n",
       " 'airport',\n",
       " 'airports',\n",
       " 'aisha',\n",
       " 'aisle',\n",
       " 'aj',\n",
       " 'ajfonemnet',\n",
       " 'ajm',\n",
       " 'ajw',\n",
       " 'ajwkwfqe',\n",
       " 'ak',\n",
       " 'aka',\n",
       " 'akargosrani',\n",
       " 'akey',\n",
       " 'akhfwnsarb',\n",
       " 'akovocifsq',\n",
       " 'al',\n",
       " 'alan',\n",
       " 'alarm',\n",
       " 'alas',\n",
       " 'alaska',\n",
       " 'alay',\n",
       " 'album',\n",
       " 'albumart',\n",
       " 'albumcover',\n",
       " 'albumpic',\n",
       " 'albums',\n",
       " 'alcala',\n",
       " 'alcohol',\n",
       " 'ale',\n",
       " 'alert',\n",
       " 'alex',\n",
       " 'alexa',\n",
       " 'alexandraeton',\n",
       " 'alexcornellier',\n",
       " 'alexionice',\n",
       " 'alexx',\n",
       " 'alfa',\n",
       " 'algerian',\n",
       " 'algonquin',\n",
       " 'alhamdulillah',\n",
       " 'alia',\n",
       " 'alibakes',\n",
       " 'alice',\n",
       " 'aliciamamo',\n",
       " 'alienware',\n",
       " 'aliexpress',\n",
       " 'align',\n",
       " 'aliusaexpress',\n",
       " 'alive',\n",
       " 'alkaline',\n",
       " 'allah',\n",
       " 'allday',\n",
       " 'alle',\n",
       " 'allege',\n",
       " 'allegedly',\n",
       " 'allen',\n",
       " 'allenchoo',\n",
       " 'allergic',\n",
       " 'allergies',\n",
       " 'allianz',\n",
       " 'alligator',\n",
       " 'alligatorskin',\n",
       " 'alligatorstrap',\n",
       " 'alliwantistoplayinfamous',\n",
       " 'allllll',\n",
       " 'alllllll',\n",
       " 'allmine',\n",
       " 'allow',\n",
       " 'allprofit',\n",
       " 'allsmiles',\n",
       " 'allstars',\n",
       " 'allstate',\n",
       " 'alltheapple',\n",
       " 'alltheway',\n",
       " 'allthose',\n",
       " 'ally',\n",
       " 'almond',\n",
       " 'almonddream',\n",
       " 'almonds',\n",
       " 'almost',\n",
       " 'almostdead',\n",
       " 'alomran',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alot',\n",
       " 'alpa',\n",
       " 'alpha',\n",
       " 'alphaa',\n",
       " 'alpine',\n",
       " 'alps',\n",
       " 'alrdy',\n",
       " 'already',\n",
       " 'also',\n",
       " 'alt',\n",
       " 'altabrisa',\n",
       " 'alternate',\n",
       " 'alternative',\n",
       " 'although',\n",
       " 'altm',\n",
       " 'alto',\n",
       " 'altruism',\n",
       " 'always',\n",
       " 'alwayscrashes',\n",
       " 'alwayslost',\n",
       " 'alwaysme',\n",
       " 'alwaysomethingbiggerandbetter',\n",
       " 'alydiano',\n",
       " 'alyssa',\n",
       " 'amagetonline',\n",
       " 'amagetstores',\n",
       " 'amaliexmaria',\n",
       " 'amandagrybowski',\n",
       " 'amani',\n",
       " 'amanzing',\n",
       " 'amapril',\n",
       " 'amateurphotography',\n",
       " 'amaz',\n",
       " 'amaze',\n",
       " 'amazingcar',\n",
       " 'amazingly',\n",
       " 'amazon',\n",
       " 'amazonalexa',\n",
       " 'amazondeal',\n",
       " 'amazonfiretv',\n",
       " 'amazonpic',\n",
       " 'amazonprimeday',\n",
       " 'amazonprme',\n",
       " 'amber',\n",
       " 'ambermaysaylor',\n",
       " 'ambreroch',\n",
       " 'amctheatres',\n",
       " 'amd',\n",
       " 'ameliaj',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americanbully',\n",
       " 'americans',\n",
       " 'amfenster',\n",
       " 'amigos',\n",
       " 'amjune',\n",
       " 'ammay',\n",
       " 'ammysmile',\n",
       " 'amnesia',\n",
       " 'amo',\n",
       " 'amomuitotudoisso',\n",
       " 'among',\n",
       " 'amor',\n",
       " 'amore',\n",
       " 'amount',\n",
       " 'amour',\n",
       " 'amp',\n",
       " 'amplicatetl',\n",
       " 'amplify',\n",
       " 'amqlwyttex',\n",
       " 'amsterdam',\n",
       " 'amuse',\n",
       " 'amwf',\n",
       " 'amyiqk',\n",
       " 'amylee',\n",
       " 'ana',\n",
       " 'anaheim',\n",
       " 'analoglondon',\n",
       " 'analogue',\n",
       " 'analyst',\n",
       " 'analysts',\n",
       " 'anarchistweeter',\n",
       " 'anberlin',\n",
       " 'anchor',\n",
       " 'anchorage',\n",
       " 'andarilho',\n",
       " 'andinobrand',\n",
       " 'anditsfinalsweek',\n",
       " 'andreaslarszon',\n",
       " 'andrew',\n",
       " 'andrewmccabe',\n",
       " 'andrewwk',\n",
       " 'andriod',\n",
       " 'android',\n",
       " 'androidalltheway',\n",
       " 'androidapp',\n",
       " 'androidcrew',\n",
       " 'androidfamily',\n",
       " 'androidftw',\n",
       " 'androidguys',\n",
       " 'androidheadline',\n",
       " 'androidinstagram',\n",
       " 'androidlife',\n",
       " 'androidnextime',\n",
       " 'androidonly',\n",
       " 'androidphone',\n",
       " 'androidpic',\n",
       " 'androidrules',\n",
       " 'androids',\n",
       " 'androidsarebetter',\n",
       " 'androidworld',\n",
       " 'andropic',\n",
       " 'andy',\n",
       " 'andyfrasco',\n",
       " 'andyger',\n",
       " 'andyvaughan',\n",
       " 'anflfunqek',\n",
       " 'anfplsx',\n",
       " 'ang',\n",
       " 'angecox',\n",
       " 'angel',\n",
       " 'angelaahrendts',\n",
       " 'angelbarrios',\n",
       " 'anger',\n",
       " 'angiemarino',\n",
       " 'angkut',\n",
       " 'angry',\n",
       " 'angrybird',\n",
       " 'angrybirds',\n",
       " 'angrylaura',\n",
       " 'angrytweet',\n",
       " 'anguyoops',\n",
       " 'aniccas',\n",
       " 'animal',\n",
       " 'animalaura',\n",
       " 'animalier',\n",
       " 'animallover',\n",
       " 'animals',\n",
       " 'animalshot',\n",
       " 'animasoft',\n",
       " 'animate',\n",
       " 'anime',\n",
       " 'animoji',\n",
       " 'anjarwarnyoto',\n",
       " 'ankara',\n",
       " 'ankuriview',\n",
       " 'anltgwc',\n",
       " 'ann',\n",
       " 'annabelle',\n",
       " 'annastainke',\n",
       " 'annieb',\n",
       " 'anniversary',\n",
       " 'anniversarygift',\n",
       " 'announce',\n",
       " 'annoy',\n",
       " 'annoyance',\n",
       " 'annoyances',\n",
       " 'annual',\n",
       " 'anon',\n",
       " 'anonymous',\n",
       " 'another',\n",
       " 'anrnjcpspk',\n",
       " 'ans',\n",
       " 'answer',\n",
       " 'antena',\n",
       " 'antenna',\n",
       " 'antennae',\n",
       " 'antennagate',\n",
       " 'anthing',\n",
       " 'anthonyli',\n",
       " 'anti',\n",
       " 'anticipation',\n",
       " 'antigua',\n",
       " 'antique',\n",
       " 'antivirus',\n",
       " 'antoine',\n",
       " 'anton',\n",
       " 'antoni',\n",
       " 'antonio',\n",
       " 'antoniotrillicoso',\n",
       " 'antwerp',\n",
       " 'anxiety',\n",
       " 'anybody',\n",
       " 'anyday',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'anz',\n",
       " 'anzde',\n",
       " 'aol',\n",
       " 'aovivo',\n",
       " 'ap',\n",
       " 'apart',\n",
       " 'apartment',\n",
       " 'apb',\n",
       " 'apctp',\n",
       " 'ape',\n",
       " 'apel',\n",
       " 'aperitif',\n",
       " 'api',\n",
       " 'apic',\n",
       " 'aplacetolive',\n",
       " 'apocalyptic',\n",
       " 'apogee',\n",
       " 'apologies',\n",
       " 'apologise',\n",
       " 'apology',\n",
       " 'app',\n",
       " 'appaltas',\n",
       " 'apparel',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'appfabulous',\n",
       " 'appgamer',\n",
       " 'appieofflciai',\n",
       " 'appl',\n",
       " 'apple',\n",
       " 'appleaddict',\n",
       " 'appleairpods',\n",
       " 'appleairport',\n",
       " 'applebees',\n",
       " 'appleboycott',\n",
       " 'applecake',\n",
       " 'applecare',\n",
       " 'applecinnamon',\n",
       " 'applecomputers',\n",
       " 'appleday',\n",
       " 'appleerror',\n",
       " 'appleevent',\n",
       " 'applefaithful',\n",
       " 'applefan',\n",
       " 'applefreak',\n",
       " 'applegeek',\n",
       " 'applegram',\n",
       " 'applehate',\n",
       " 'appleholicpic',\n",
       " 'appleid',\n",
       " 'appleidiots',\n",
       " 'appleiie',\n",
       " 'appleiosupdate',\n",
       " 'appleiphone',\n",
       " 'appleis',\n",
       " 'appleismonopolyandripoff',\n",
       " 'appleisshit',\n",
       " 'appleisstupid',\n",
       " 'appleit',\n",
       " 'applelife',\n",
       " 'applemacbook',\n",
       " 'appleman',\n",
       " 'applemaniac',\n",
       " 'applemaps',\n",
       " 'applemusic',\n",
       " 'applenerd',\n",
       " 'applenofuture',\n",
       " 'applenws',\n",
       " 'appleofficiai',\n",
       " 'appleofficialll',\n",
       " 'appleofficlal',\n",
       " 'appleonly',\n",
       " 'applepay',\n",
       " 'applepic',\n",
       " 'applepie',\n",
       " 'apples',\n",
       " 'applestore',\n",
       " 'applestoreistanbul',\n",
       " 'applestores',\n",
       " 'applesucks',\n",
       " 'applesupport',\n",
       " 'applesux',\n",
       " 'appletech',\n",
       " 'appleton',\n",
       " 'appletrifle',\n",
       " 'appleturnoverday',\n",
       " 'appletv',\n",
       " 'appleuk',\n",
       " 'appleukofficial',\n",
       " 'applewach',\n",
       " 'applewatch',\n",
       " 'applewatchband',\n",
       " 'applewatchpic',\n",
       " 'applewatchseries',\n",
       " 'applewatchsport',\n",
       " 'application',\n",
       " 'applle',\n",
       " 'applover',\n",
       " 'apply',\n",
       " 'appointment',\n",
       " 'appointments',\n",
       " 'appotment',\n",
       " 'appreciate',\n",
       " 'apprentice',\n",
       " 'appreview',\n",
       " 'approach',\n",
       " 'approve',\n",
       " 'approximately',\n",
       " 'apps',\n",
       " 'appstore',\n",
       " 'appstrore',\n",
       " 'appsworld',\n",
       " 'appts',\n",
       " 'april',\n",
       " 'apts',\n",
       " 'apvma',\n",
       " 'apw',\n",
       " 'aqua',\n",
       " 'aquaris',\n",
       " 'ar',\n",
       " 'arab',\n",
       " 'araba',\n",
       " 'arabian',\n",
       " 'arabic',\n",
       " 'arabiceyes',\n",
       " 'aragua',\n",
       " 'arcadia',\n",
       " 'archite',\n",
       " 'architect',\n",
       " 'architecten',\n",
       " 'architecture',\n",
       " 'architektur',\n",
       " 'archive',\n",
       " 'arduous',\n",
       " 'area',\n",
       " 'arequipa',\n",
       " 'areyoukiddingme',\n",
       " 'argentina',\n",
       " 'argh',\n",
       " 'arghhhhhh',\n",
       " 'arginine',\n",
       " 'argue',\n",
       " 'ari',\n",
       " 'arianastansareskinny',\n",
       " 'arianasurprise',\n",
       " 'ariane',\n",
       " 'ariel',\n",
       " 'arielramdeen',\n",
       " 'arizona',\n",
       " 'arkit',\n",
       " 'arm',\n",
       " 'armada',\n",
       " 'armageddon',\n",
       " 'armani',\n",
       " 'armband',\n",
       " 'armcandy',\n",
       " 'armenian',\n",
       " 'army',\n",
       " 'armygirl',\n",
       " 'around',\n",
       " 'aroundme',\n",
       " 'arquitectura',\n",
       " 'arrival',\n",
       " 'arrivals',\n",
       " 'arrive',\n",
       " 'arrn',\n",
       " 'arrogant',\n",
       " 'arrogent',\n",
       " 'arrow',\n",
       " 'arrows',\n",
       " 'arrr',\n",
       " 'arrrrgggghhhhhhh',\n",
       " 'arrrrrrgggggggggggg',\n",
       " 'arsalanchipic',\n",
       " 'arschsaft',\n",
       " 'arse',\n",
       " 'arsed',\n",
       " 'arseholes',\n",
       " 'arsenal',\n",
       " 'art',\n",
       " 'arte',\n",
       " 'artgallery',\n",
       " 'article',\n",
       " 'artificialintelligence',\n",
       " 'artist',\n",
       " 'artista',\n",
       " 'artistic',\n",
       " 'artistsontwitter',\n",
       " 'artofpo',\n",
       " 'artofportr',\n",
       " 'artofportrait',\n",
       " 'artoftheday',\n",
       " 'artphoto',\n",
       " 'artphotography',\n",
       " 'artphotos',\n",
       " 'artpic',\n",
       " 'artpop',\n",
       " 'arts',\n",
       " 'artsociety',\n",
       " 'artwork',\n",
       " 'arty',\n",
       " 'aruba',\n",
       " 'arunganesan',\n",
       " 'asap',\n",
       " 'asburypark',\n",
       " 'asburyparkboardwalk',\n",
       " 'ascend',\n",
       " 'ascii',\n",
       " 'aseries',\n",
       " 'asfhxxyhzj',\n",
       " 'ash',\n",
       " 'ashdod',\n",
       " 'ashford',\n",
       " 'ashleyalexiss',\n",
       " 'ashleyriach',\n",
       " 'ashole',\n",
       " 'ashtag',\n",
       " 'asia',\n",
       " 'asian',\n",
       " 'asiangirl',\n",
       " 'aside',\n",
       " 'asjq',\n",
       " 'ask',\n",
       " 'askdrandrew',\n",
       " 'askmeanything',\n",
       " 'askquestions',\n",
       " 'askzayn',\n",
       " 'asleep',\n",
       " 'asokoro',\n",
       " 'asos',\n",
       " 'asot',\n",
       " 'aspects',\n",
       " 'aspettiamo',\n",
       " 'ass',\n",
       " 'assassinscreed',\n",
       " 'assault',\n",
       " 'assembly',\n",
       " 'asses',\n",
       " 'assfaces',\n",
       " 'assfuck',\n",
       " 'asshole',\n",
       " 'assholes',\n",
       " 'assistance',\n",
       " 'assistant',\n",
       " 'assjuice',\n",
       " 'assume',\n",
       " 'asthma',\n",
       " 'aston',\n",
       " 'astonmartin',\n",
       " 'astound',\n",
       " 'astro',\n",
       " 'aswell',\n",
       " 'atandtservice',\n",
       " 'atelier',\n",
       " 'atexwxarl',\n",
       " 'atheist',\n",
       " 'athens',\n",
       " 'athlete',\n",
       " 'ativ',\n",
       " 'atlanta',\n",
       " 'atlantic',\n",
       " 'atm',\n",
       " 'atmashelter',\n",
       " 'atomium',\n",
       " 'atop',\n",
       " 'atrix',\n",
       " 'atrt',\n",
       " 'ats',\n",
       " 'att',\n",
       " 'attach',\n",
       " 'attack',\n",
       " 'attain',\n",
       " 'attempt',\n",
       " 'attendees',\n",
       " 'attention',\n",
       " 'attimes',\n",
       " 'attitude',\n",
       " 'atwfkn',\n",
       " 'atx',\n",
       " 'atxdogs',\n",
       " 'aubkpyjzwj',\n",
       " 'auch',\n",
       " 'auction',\n",
       " 'aud',\n",
       " 'audacity',\n",
       " 'audi',\n",
       " 'audio',\n",
       " 'audiophiles',\n",
       " 'audiosystem',\n",
       " 'audition',\n",
       " 'aug',\n",
       " 'augmentedreality',\n",
       " 'august',\n",
       " 'auh',\n",
       " 'aunction',\n",
       " 'aunty',\n",
       " 'aura',\n",
       " 'auriculares',\n",
       " 'aurora',\n",
       " 'aurorabeauty',\n",
       " 'aus',\n",
       " 'aussie',\n",
       " 'austin',\n",
       " 'australia',\n",
       " 'australianshepherd',\n",
       " 'australiapic',\n",
       " 'authentic',\n",
       " 'authoritypic',\n",
       " 'auto',\n",
       " 'autocad',\n",
       " 'autocorrect',\n",
       " 'autocorrecting',\n",
       " 'autofix',\n",
       " 'autograph',\n",
       " 'automate',\n",
       " 'automatedsystem',\n",
       " 'automatic',\n",
       " 'automatically',\n",
       " 'autumn',\n",
       " 'autumnpic',\n",
       " 'auuhkx',\n",
       " 'aux',\n",
       " 'av',\n",
       " 'avail',\n",
       " 'available',\n",
       " 'avatar',\n",
       " 'avday',\n",
       " 'ave',\n",
       " 'avengers',\n",
       " 'avenue',\n",
       " 'average',\n",
       " 'avgeek',\n",
       " 'avi',\n",
       " 'aviary',\n",
       " 'aviation',\n",
       " 'avicii',\n",
       " 'avid',\n",
       " 'avikalchhetri',\n",
       " 'avit',\n",
       " 'avm',\n",
       " 'avocadoe',\n",
       " 'avoid',\n",
       " 'avtweeps',\n",
       " 'avtweetup',\n",
       " 'avvqn',\n",
       " 'aw',\n",
       " 'await',\n",
       " 'awake',\n",
       " 'award',\n",
       " 'aware',\n",
       " 'awareness',\n",
       " 'away',\n",
       " 'awdqysqlzg',\n",
       " 'awesome',\n",
       " 'awesomeness',\n",
       " 'awesomeone',\n",
       " 'awesomepic',\n",
       " 'awesomized',\n",
       " 'awfmyf',\n",
       " 'awful',\n",
       " 'awh',\n",
       " 'awhile',\n",
       " 'awks',\n",
       " 'awkward',\n",
       " 'awolnation',\n",
       " 'awsome',\n",
       " 'aww',\n",
       " 'awww',\n",
       " 'awwww',\n",
       " 'awwwww',\n",
       " 'awzshauqbk',\n",
       " 'ax',\n",
       " 'axhqqwwf',\n",
       " 'ayaq',\n",
       " 'aynfj',\n",
       " 'ayob',\n",
       " 'ayodya',\n",
       " 'aysku',\n",
       " 'az',\n",
       " 'azerbaijan',\n",
       " 'aztec',\n",
       " 'ba',\n",
       " 'baaaby',\n",
       " 'baba',\n",
       " 'babe',\n",
       " 'babecaughtmesleeping',\n",
       " 'babhvvycud',\n",
       " 'babi',\n",
       " 'babolat',\n",
       " 'baby',\n",
       " 'babyboy',\n",
       " 'babycousin',\n",
       " 'babygirl',\n",
       " 'babylove',\n",
       " 'babymuscles',\n",
       " 'babyyy',\n",
       " 'back',\n",
       " 'backbone',\n",
       " 'backcountry',\n",
       " 'backcover',\n",
       " 'backend',\n",
       " 'backface',\n",
       " 'background',\n",
       " 'backlit',\n",
       " 'backontrack',\n",
       " 'backordered',\n",
       " 'backpack',\n",
       " 'backpacker',\n",
       " 'backtocollege',\n",
       " 'backup',\n",
       " 'backups',\n",
       " 'backyard',\n",
       " 'bacon',\n",
       " 'baconeggandcheese',\n",
       " 'bacterial',\n",
       " 'bad',\n",
       " 'bada',\n",
       " 'badass',\n",
       " 'baddiel',\n",
       " 'badge',\n",
       " 'badgirlsclub',\n",
       " 'badiphone',\n",
       " 'badkamer',\n",
       " 'badly',\n",
       " 'badmemories',\n",
       " 'badminton',\n",
       " 'bado',\n",
       " 'badpic',\n",
       " 'badquality',\n",
       " 'badtimes',\n",
       " 'badu',\n",
       " 'bae',\n",
       " 'baffins',\n",
       " 'bag',\n",
       " 'bagel',\n",
       " 'baggy',\n",
       " 'bagi',\n",
       " 'bagofshite',\n",
       " 'bagriders',\n",
       " 'bahaha',\n",
       " 'bahahahahahahah',\n",
       " 'bahrain',\n",
       " 'bahraini',\n",
       " 'baii',\n",
       " 'bait',\n",
       " 'baju',\n",
       " 'baka',\n",
       " 'bake',\n",
       " 'baker',\n",
       " 'bakery',\n",
       " 'bako',\n",
       " 'baku',\n",
       " 'balance',\n",
       " 'baldwin',\n",
       " 'bali',\n",
       " 'balker',\n",
       " 'ball',\n",
       " 'balla',\n",
       " 'baller',\n",
       " 'ballerina',\n",
       " 'ballern',\n",
       " 'ballet',\n",
       " 'balloon',\n",
       " 'bam',\n",
       " 'bamboo',\n",
       " 'ban',\n",
       " 'banana',\n",
       " 'bananas',\n",
       " 'band',\n",
       " 'bandede',\n",
       " 'bandeges',\n",
       " 'bandel',\n",
       " 'bandicoot',\n",
       " 'bandung',\n",
       " 'bandwagon',\n",
       " 'bang',\n",
       " 'bangalore',\n",
       " 'bangkok',\n",
       " 'bangolufsen',\n",
       " 'banjaran',\n",
       " 'bank',\n",
       " 'bankholiday',\n",
       " 'bankholidaymonday',\n",
       " 'bankholidayweekend',\n",
       " 'bankrupt',\n",
       " 'banner',\n",
       " 'banter',\n",
       " 'baphonicas',\n",
       " 'bar',\n",
       " 'barbados',\n",
       " 'barber',\n",
       " 'barbershop',\n",
       " 'barcelona',\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4252    cool car wash idea theisland bankholidaymonday...\n",
       "4428    photo th birthday sony walkman thinkgeek nobod...\n",
       "7374    ipads biggest pile fuck planet want throw fuck...\n",
       "1410    yearbook hmmmmm instagram instagood together f...\n",
       "7896    piss macbook crash apple company nothing apple...\n",
       "                              ...                        \n",
       "5226    shana tova jewish newyear everyone may new yea...\n",
       "5390               sick buy new cell phone chargers apple\n",
       "860     want download free iphone app today spread sty...\n",
       "7603    photo nikosx iphone beach holiday bw iphone bl...\n",
       "7270    get iphone hehe iphone apple new finally seb lose\n",
       "Name: cleaned_tweets, Length: 6336, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "GNB=GaussianNB()\n",
    "GNB.fit(x_train_mat.toarray(),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8025426887187398\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "pre=GNB.predict(x_test_mat.toarray())\n",
    "print(f1_score(y_test,pre,average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7921</td>\n",
       "      <td>I hate the new #iphone upgrade. Won't let me d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7922</td>\n",
       "      <td>currently shitting my fucking pants. #apple #i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7923</td>\n",
       "      <td>I'd like to puts some CD-ROMS on my iPad, is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7924</td>\n",
       "      <td>My ipod is officially dead. I lost all my pict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7925</td>\n",
       "      <td>Been fighting iTunes all night! I only want th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              tweet\n",
       "0  7921  I hate the new #iphone upgrade. Won't let me d...\n",
       "1  7922  currently shitting my fucking pants. #apple #i...\n",
       "2  7923  I'd like to puts some CD-ROMS on my iPad, is t...\n",
       "3  7924  My ipod is officially dead. I lost all my pict...\n",
       "4  7925  Been fighting iTunes all night! I only want th..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=pd.read_csv('test_oJQbWVk.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['cleaned_tweets']=test['tweet'].apply(lambda x:preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfidf_transform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-ef526fdf1779>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_mat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtfidf_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cleaned_tweets'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tfidf_transform' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "test_mat=tfidf_transform(test['cleaned_tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pre=GNB.predict(test_mat.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
